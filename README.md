# ğŸ™ï¸ AI Voice Assistant (Python + OpenAI GPT-4o-mini)

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue.svg)](https://www.python.org/)
[![OpenAI API](https://img.shields.io/badge/OpenAI-GPT--4o--mini-green.svg)](https://platform.openai.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

An intelligent **voice-controlled AI assistant** built in Python that listens to your commands, understands natural language using **OpenAIâ€™s GPT-4o-mini**, and responds with **speech**.  
It can open websites, desktop applications, tell the time/date, and answer questions â€” just like a personal smart assistant!

---

## ğŸš€ Features

âœ… Voice recognition using `SpeechRecognition`  
âœ… Text-to-speech replies via `pyttsx3`  
âœ… AI-powered responses using **GPT-4o-mini**  
âœ… Opens apps and popular websites (YouTube, WhatsApp, LinkedIn, etc.)  
âœ… Continuous listening loop for interactive conversation  

---

## ğŸ§© Tech Stack

| Component | Library / Tool |
|------------|----------------|
| AI Model | OpenAI GPT-4o-mini |
| Speech Recognition | `speech_recognition`, `PyAudio` |
| Text-to-Speech | `pyttsx3` |
| Environment | Python 3.10+ |
| Platform | Windows (recommended) |

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/YOUR_USERNAME/ai-assistant.git
cd ai-assistant
````

### 2ï¸âƒ£ Create a Virtual Environment

```bash
python -m venv venv
venv\Scripts\activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configure Environment Variables

Create a `.env` file in the project root:

```bash
# .env
OPENAI_API_KEY=your_OpenApi_key
MODEL=gpt-4o-mini
```

> ğŸ’¡ **Important:**
> Never expose your real API key in public repositories.
> Use the `.env` file locally and make sure `.gitignore` includes it (which it does).

---

### 5ï¸âƒ£ Run the Assistant

```bash
python assistant.py
```

Youâ€™ll hear:

> ğŸ§ â€œHello, I am your AI assistant. How can I help you?â€

Now start speaking â€” for example:

* â€œOpen YouTubeâ€
* â€œTell me about Elon Muskâ€
* â€œWhatâ€™s the time?â€
* â€œOpen LinkedInâ€
* â€œWho invented Tesla?â€

---

## ğŸ“ Project Structure

```
ai-assistant/
â”‚
â”œâ”€â”€ assistant.py          # Main AI assistant code
â”œâ”€â”€ requirements.txt      # Dependencies
â”œâ”€â”€ .env                  # API keys (ignored by Git)
â”œâ”€â”€ .gitignore            # Ignore system and venv files
â””â”€â”€ README.md             # Project documentation
```

---

## ğŸ“¦ Example Commands

| Command                   | What It Does                     |
| ------------------------- | -------------------------------- |
| â€œOpen YouTubeâ€            | Launches YouTube in your browser |
| â€œWhatâ€™s the time?â€        | Speaks the current time          |
| â€œTell me about Elon Muskâ€ | GPT explains Elon Musk in voice  |
| â€œOpen WhatsAppâ€           | Opens WhatsApp Web               |
| â€œExitâ€                    | Ends the assistant               |

---

## ğŸ§  How It Works

1. Your voice is captured using the microphone (`SpeechRecognition`).
2. Converted to text via Google Speech API.
3. The text is sent to **OpenAI GPT-4o-mini** for understanding.
4. The response is spoken aloud using `pyttsx3`.

---



